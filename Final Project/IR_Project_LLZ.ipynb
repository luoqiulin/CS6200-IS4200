{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9vumeRzePde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828e0759-1391-463e-f1b0-770aaa8eeded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tmdbsimple\n",
            "  Downloading tmdbsimple-2.9.1-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tmdbsimple) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tmdbsimple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tmdbsimple) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tmdbsimple) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tmdbsimple) (1.24.3)\n",
            "Installing collected packages: tmdbsimple\n",
            "Successfully installed tmdbsimple-2.9.1\n"
          ]
        }
      ],
      "source": [
        "pip install tmdbsimple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXlPVw6qcdAp"
      },
      "outputs": [],
      "source": [
        "import tmdbsimple as tmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V20NlZ6hfkLR"
      },
      "outputs": [],
      "source": [
        "# requires api key that needs project url and personal info etc.\n",
        "# not sure if i want to continue\n",
        "# sticking with existing dataset for now..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59CPCaK8PmOQ"
      },
      "source": [
        "# **Building corpus**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK9QTfThF50j"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is taken from Kaggle: \"Wikipedia Movie Plots\" \n",
        "https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots\n"
      ],
      "metadata": {
        "id": "UvosUdkAL98n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjQ1yND_Plxj"
      },
      "outputs": [],
      "source": [
        "# if working in colab\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "file = files.upload()\n",
        "df = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TYCvESlzrfw"
      },
      "outputs": [],
      "source": [
        "# If working in local:\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znufX6vcLyV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94f4253-3fb8-4b0c-9017-8264221648fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast',\n",
              "       'Genre', 'Wiki Page', 'Plot'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KDVYkb-cLyV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe41f8e2-7af6-409d-9941-da3996aa552f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34886 entries, 0 to 34885\n",
            "Data columns (total 8 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   Release Year      34886 non-null  int64 \n",
            " 1   Title             34886 non-null  object\n",
            " 2   Origin/Ethnicity  34886 non-null  object\n",
            " 3   Director          34886 non-null  object\n",
            " 4   Cast              33464 non-null  object\n",
            " 5   Genre             34886 non-null  object\n",
            " 6   Wiki Page         34886 non-null  object\n",
            " 7   Plot              34886 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuA0S_HnPlvW"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Id18UCBLyV5"
      },
      "source": [
        "Check file structure. Notice that there are null values in \"cast\" and there are some unknown values in other columns. Replace null with empty string for now and deal with unknown values later (unknown and Unknown...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg7iiWrnLyV6"
      },
      "outputs": [],
      "source": [
        "data_cols = ['Title', 'Origin/Ethnicity', 'Director', 'Cast', 'Genre', 'Plot']\n",
        "collection = df[data_cols]\n",
        "collection = collection.apply(lambda x: x.str.lower())\n",
        "# not sure if \"unknown values\" should be replaced with empty string...\n",
        "collection = collection.fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KNGwYuRyLyV6",
        "outputId": "434d804c-c032-4b31-d73b-0a3160499c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Title': 2, 'Origin/Ethnicity': 0, 'Director': 1124, 'Cast': 1, 'Genre': 6083, 'Plot': 0}\n"
          ]
        }
      ],
      "source": [
        "unknown = {\n",
        "    col: collection.loc[collection[col]=='unknown',col].count()\n",
        "    for col in collection.columns\n",
        "}\n",
        "print(unknown) # relatively small proportion.. probably won't affect the result too much"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu_-zKdNLyV6"
      },
      "source": [
        "## Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwqFndSLLyV6",
        "outputId": "0b9bdaf9-35e9-4792-9992-a15a00b3fe62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re\n",
        "import string # for punctuations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbT92gOqLyV7"
      },
      "outputs": [],
      "source": [
        "# Initialize a tokenizer\n",
        "tokenizer = WhitespaceTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DBUuHPYULyV7"
      },
      "outputs": [],
      "source": [
        "# Tokenize columns \n",
        "\n",
        "tokenized_df = pd.DataFrame()\n",
        "for col in collection.columns:\n",
        "    pre_tokenize = collection[col].apply(lambda row : row.replace(\"\\n\",\" \").replace(\n",
        "        \"'s\",\" \").translate(str.maketrans(dict.fromkeys(string.punctuation,\" \"))))\n",
        "    new_col_name = col+'_Tokenized'\n",
        "    tokenized_df[new_col_name] = pre_tokenize\n",
        "    tokenized_df[new_col_name] = tokenized_df[new_col_name].apply(lambda x: tokenizer.tokenize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "05MSvrMgLyV7"
      },
      "outputs": [],
      "source": [
        "# Combining tokens from different fields\n",
        "tokenized_df['Tokens'] = tokenized_df['Title_Tokenized'] + tokenized_df['Origin/Ethnicity_Tokenized'] + tokenized_df['Director_Tokenized'] + tokenized_df['Cast_Tokenized'] + tokenized_df['Genre_Tokenized'] + tokenized_df['Plot_Tokenized']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0drVzzLxLyV7",
        "outputId": "034844bd-cc14-409e-fe5d-0dedd5b383d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Title_Tokenized', 'Origin/Ethnicity_Tokenized', 'Director_Tokenized',\n",
              "       'Cast_Tokenized', 'Genre_Tokenized', 'Plot_Tokenized', 'Tokens'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenized_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9ZSgK--LyV7",
        "outputId": "647a5698-ee28-44f6-b367-7ac29bb7e6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         90\n",
              "1         96\n",
              "2         83\n",
              "3        162\n",
              "4        152\n",
              "        ... \n",
              "34881    618\n",
              "34882     22\n",
              "34883     79\n",
              "34884    221\n",
              "34885     63\n",
              "Name: Tokens, Length: 34886, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenized_df['Tokens'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZJ04GicPltW"
      },
      "outputs": [],
      "source": [
        "# Removing stopwords\n",
        "stop = stopwords.words('english')\n",
        "tokenized_df['Tokens'] = tokenized_df['Tokens'].apply(lambda x: [tk for tk in x if tk not in stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLuei9F2LyV8",
        "outputId": "64ce09f0-a39b-4e07-c58e-e789e1632e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         55\n",
              "1         50\n",
              "2         47\n",
              "3         93\n",
              "4         79\n",
              "        ... \n",
              "34881    366\n",
              "34882     18\n",
              "34883     50\n",
              "34884    137\n",
              "34885     43\n",
              "Name: Tokens, Length: 34886, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokenized_df['Tokens'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qnQe0jvLyV8"
      },
      "outputs": [],
      "source": [
        "# len(set(stopwords.words('english')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Cd14y-bJLyV8"
      },
      "outputs": [],
      "source": [
        "# Document - tokens dictionary (or df?)\n",
        "# doc_tokens = dict()\n",
        "#for i in range(len(tokenized_df)):\n",
        "#    doc_tokens[i] = token "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmXMuDNoPliG"
      },
      "outputs": [],
      "source": [
        "# v2 using regular expressions\n",
        "# save for later\n",
        "# tokenized_df_v2 = pd.DataFrame()\n",
        "# for col in collection.columns:\n",
        "#     pre_tokenize = collection[col].apply(lambda row : row.replace(\"\\n\",\" \").replace(\n",
        "#         \"'s\",\" \").translate(str.maketrans(dict.fromkeys(string.punctuation,\" \"))))\n",
        "#     new_col_name = col+'_Tokenized'\n",
        "#     pre_tokenize = pre_tokenize.apply(lambda x: re.sub(r'[\\W_]', ' ', x))\n",
        "#     pre_tokenize = pre_tokenize.apply(lambda x: re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x))\n",
        "#     pre_tokenize = pre_tokenize.apply(lambda x: re.sub(r'\\^[a-zA-Z]\\s+', ' ', x))\n",
        "#     pre_tokenize = pre_tokenize.apply(lambda x: re.sub(r'\\s+', ' ', x, flags=re.I))\n",
        "#     pre_tokenize = pre_tokenize.apply(lambda x: re.sub(r'^b\\s+', '', x))\n",
        "#     tokenized = pre_tokenize.apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', ' ', x))\n",
        "#     tokenized_df_v2[new_col_name] = tokenized\n",
        "\n",
        "# re tokenizes strings so needs a different method to combine all the tokens together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEksudgeLyV8"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLhZJ1byLyV8"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_183cTLyV9"
      },
      "outputs": [],
      "source": [
        "tokenized_df['Stemmed'] = tokenized_df['Tokens'].apply(lambda x: [stemmer.stem(token) for token in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zCfK9KMyLyV9",
        "outputId": "02088269-e1c8-4dfb-dd33-3d52c50330b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         55\n",
              "1         50\n",
              "2         47\n",
              "3         93\n",
              "4         79\n",
              "        ... \n",
              "34881    366\n",
              "34882     18\n",
              "34883     50\n",
              "34884    137\n",
              "34885     43\n",
              "Name: Stemmed, Length: 34886, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenized_df['Stemmed'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3wTixPXLyV9",
        "outputId": "35c78d75-0f68-4222-80c9-afaa4e61a2ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [kansa, saloon, smasher, american, unknown, un...\n",
              "1    [love, light, moon, american, unknown, unknown...\n",
              "Name: Stemmed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenized_df['Stemmed'][:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_df"
      ],
      "metadata": {
        "id": "rm43SdxTfl0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcf5cf8-5769-4ecc-9fd4-bdae4330f130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Title_Tokenized Origin/Ethnicity_Tokenized  \\\n",
              "0                 [kansas, saloon, smashers]                 [american]   \n",
              "1      [love, by, the, light, of, the, moon]                 [american]   \n",
              "2                [the, martyred, presidents]                 [american]   \n",
              "3      [terrible, teddy, the, grizzly, king]                 [american]   \n",
              "4                [jack, and, the, beanstalk]                 [american]   \n",
              "...                                      ...                        ...   \n",
              "34881                  [the, water, diviner]                  [turkish]   \n",
              "34882                [çalgı, çengi, i̇kimiz]                  [turkish]   \n",
              "34883                        [olanlar, oldu]                  [turkish]   \n",
              "34884                    [non, transferable]                  [turkish]   \n",
              "34885                 [i̇stanbul, kırmızısı]                  [turkish]   \n",
              "\n",
              "                           Director_Tokenized  \\\n",
              "0                                   [unknown]   \n",
              "1                                   [unknown]   \n",
              "2                                   [unknown]   \n",
              "3                                   [unknown]   \n",
              "4      [george, s, fleming, edwin, s, porter]   \n",
              "...                                       ...   \n",
              "34881              [director, russell, crowe]   \n",
              "34882                       [selçuk, aydemir]   \n",
              "34883                          [hakan, algül]   \n",
              "34884                      [brendan, bradley]   \n",
              "34885                       [ferzan, özpetek]   \n",
              "\n",
              "                                          Cast_Tokenized     Genre_Tokenized  \\\n",
              "0                                                     []           [unknown]   \n",
              "1                                                     []           [unknown]   \n",
              "2                                                     []           [unknown]   \n",
              "3                                                     []           [unknown]   \n",
              "4                                                     []           [unknown]   \n",
              "...                                                  ...                 ...   \n",
              "34881  [director, russell, crowe, cast, russell, crow...           [unknown]   \n",
              "34882                      [ahmet, kural, murat, cemcir]            [comedy]   \n",
              "34883         [ata, demirer, tuvana, türkay, ülkü, duru]            [comedy]   \n",
              "34884  [youtubers, shanna, malcolm, shira, lazar, sar...  [romantic, comedy]   \n",
              "34885  [halit, ergenç, tuba, büyüküstün, mehmet, güns...          [romantic]   \n",
              "\n",
              "                                          Plot_Tokenized  \\\n",
              "0      [a, bartender, is, working, at, a, saloon, ser...   \n",
              "1      [the, moon, painted, with, a, smiling, face, h...   \n",
              "2      [the, film, just, over, a, minute, long, is, c...   \n",
              "3      [lasting, just, 61, seconds, and, consisting, ...   \n",
              "4      [the, earliest, known, adaptation, of, the, cl...   \n",
              "...                                                  ...   \n",
              "34881  [the, film, begins, in, 1919, just, after, wor...   \n",
              "34882  [two, musicians, salih, and, gürkan, described...   \n",
              "34883  [zafer, a, sailor, living, with, his, mother, ...   \n",
              "34884  [the, film, centres, around, a, young, woman, ...   \n",
              "34885  [the, writer, orhan, şahin, returns, to, i̇sta...   \n",
              "\n",
              "                                                  Tokens  \\\n",
              "0      [kansas, saloon, smashers, american, unknown, ...   \n",
              "1      [love, light, moon, american, unknown, unknown...   \n",
              "2      [martyred, presidents, american, unknown, unkn...   \n",
              "3      [terrible, teddy, grizzly, king, american, unk...   \n",
              "4      [jack, beanstalk, american, george, fleming, e...   \n",
              "...                                                  ...   \n",
              "34881  [water, diviner, turkish, director, russell, c...   \n",
              "34882  [çalgı, çengi, i̇kimiz, turkish, selçuk, aydem...   \n",
              "34883  [olanlar, oldu, turkish, hakan, algül, ata, de...   \n",
              "34884  [non, transferable, turkish, brendan, bradley,...   \n",
              "34885  [i̇stanbul, kırmızısı, turkish, ferzan, özpete...   \n",
              "\n",
              "                                                 Stemmed  \n",
              "0      [kansa, saloon, smasher, american, unknown, un...  \n",
              "1      [love, light, moon, american, unknown, unknown...  \n",
              "2      [martyr, presid, american, unknown, unknown, f...  \n",
              "3      [terribl, teddi, grizzli, king, american, unkn...  \n",
              "4      [jack, beanstalk, american, georg, fleme, edwi...  \n",
              "...                                                  ...  \n",
              "34881  [water, divin, turkish, director, russel, crow...  \n",
              "34882  [çalgı, çengi, i̇kimiz, turkish, selçuk, aydem...  \n",
              "34883  [olanlar, oldu, turkish, hakan, algül, ata, de...  \n",
              "34884  [non, transfer, turkish, brendan, bradley, you...  \n",
              "34885  [i̇stanbul, kırmızısı, turkish, ferzan, özpete...  \n",
              "\n",
              "[34886 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8148e992-7275-4cf5-b024-3fb935881280\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title_Tokenized</th>\n",
              "      <th>Origin/Ethnicity_Tokenized</th>\n",
              "      <th>Director_Tokenized</th>\n",
              "      <th>Cast_Tokenized</th>\n",
              "      <th>Genre_Tokenized</th>\n",
              "      <th>Plot_Tokenized</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[kansas, saloon, smashers]</td>\n",
              "      <td>[american]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[a, bartender, is, working, at, a, saloon, ser...</td>\n",
              "      <td>[kansas, saloon, smashers, american, unknown, ...</td>\n",
              "      <td>[kansa, saloon, smasher, american, unknown, un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[love, by, the, light, of, the, moon]</td>\n",
              "      <td>[american]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[the, moon, painted, with, a, smiling, face, h...</td>\n",
              "      <td>[love, light, moon, american, unknown, unknown...</td>\n",
              "      <td>[love, light, moon, american, unknown, unknown...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[the, martyred, presidents]</td>\n",
              "      <td>[american]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[the, film, just, over, a, minute, long, is, c...</td>\n",
              "      <td>[martyred, presidents, american, unknown, unkn...</td>\n",
              "      <td>[martyr, presid, american, unknown, unknown, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[terrible, teddy, the, grizzly, king]</td>\n",
              "      <td>[american]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[lasting, just, 61, seconds, and, consisting, ...</td>\n",
              "      <td>[terrible, teddy, grizzly, king, american, unk...</td>\n",
              "      <td>[terribl, teddi, grizzli, king, american, unkn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[jack, and, the, beanstalk]</td>\n",
              "      <td>[american]</td>\n",
              "      <td>[george, s, fleming, edwin, s, porter]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[the, earliest, known, adaptation, of, the, cl...</td>\n",
              "      <td>[jack, beanstalk, american, george, fleming, e...</td>\n",
              "      <td>[jack, beanstalk, american, georg, fleme, edwi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34881</th>\n",
              "      <td>[the, water, diviner]</td>\n",
              "      <td>[turkish]</td>\n",
              "      <td>[director, russell, crowe]</td>\n",
              "      <td>[director, russell, crowe, cast, russell, crow...</td>\n",
              "      <td>[unknown]</td>\n",
              "      <td>[the, film, begins, in, 1919, just, after, wor...</td>\n",
              "      <td>[water, diviner, turkish, director, russell, c...</td>\n",
              "      <td>[water, divin, turkish, director, russel, crow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34882</th>\n",
              "      <td>[çalgı, çengi, i̇kimiz]</td>\n",
              "      <td>[turkish]</td>\n",
              "      <td>[selçuk, aydemir]</td>\n",
              "      <td>[ahmet, kural, murat, cemcir]</td>\n",
              "      <td>[comedy]</td>\n",
              "      <td>[two, musicians, salih, and, gürkan, described...</td>\n",
              "      <td>[çalgı, çengi, i̇kimiz, turkish, selçuk, aydem...</td>\n",
              "      <td>[çalgı, çengi, i̇kimiz, turkish, selçuk, aydem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34883</th>\n",
              "      <td>[olanlar, oldu]</td>\n",
              "      <td>[turkish]</td>\n",
              "      <td>[hakan, algül]</td>\n",
              "      <td>[ata, demirer, tuvana, türkay, ülkü, duru]</td>\n",
              "      <td>[comedy]</td>\n",
              "      <td>[zafer, a, sailor, living, with, his, mother, ...</td>\n",
              "      <td>[olanlar, oldu, turkish, hakan, algül, ata, de...</td>\n",
              "      <td>[olanlar, oldu, turkish, hakan, algül, ata, de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34884</th>\n",
              "      <td>[non, transferable]</td>\n",
              "      <td>[turkish]</td>\n",
              "      <td>[brendan, bradley]</td>\n",
              "      <td>[youtubers, shanna, malcolm, shira, lazar, sar...</td>\n",
              "      <td>[romantic, comedy]</td>\n",
              "      <td>[the, film, centres, around, a, young, woman, ...</td>\n",
              "      <td>[non, transferable, turkish, brendan, bradley,...</td>\n",
              "      <td>[non, transfer, turkish, brendan, bradley, you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34885</th>\n",
              "      <td>[i̇stanbul, kırmızısı]</td>\n",
              "      <td>[turkish]</td>\n",
              "      <td>[ferzan, özpetek]</td>\n",
              "      <td>[halit, ergenç, tuba, büyüküstün, mehmet, güns...</td>\n",
              "      <td>[romantic]</td>\n",
              "      <td>[the, writer, orhan, şahin, returns, to, i̇sta...</td>\n",
              "      <td>[i̇stanbul, kırmızısı, turkish, ferzan, özpete...</td>\n",
              "      <td>[i̇stanbul, kırmızısı, turkish, ferzan, özpete...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34886 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8148e992-7275-4cf5-b024-3fb935881280')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8148e992-7275-4cf5-b024-3fb935881280 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8148e992-7275-4cf5-b024-3fb935881280');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDFcY797LyV9"
      },
      "source": [
        "# **Building index & tf-idf weights**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTIhxWJaLyV9"
      },
      "source": [
        "## Building inverted index & frequency counters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCws5rDoLyV9"
      },
      "source": [
        "Using tokens from all fields in the dataframe at the moment. Might consider separate out specific fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCM5re7ELyV9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-el2tbsWLyV9"
      },
      "outputs": [],
      "source": [
        "# Building word-count dictionary for each document - \"bag of words\"\n",
        "doc_tokens_dict = dict(zip(tokenized_df.index, tokenized_df['Stemmed']))\n",
        "for k in doc_tokens_dict.keys():\n",
        "    words = doc_tokens_dict[k]\n",
        "    counter = Counter(words)\n",
        "    doc_tokens_dict[k] = counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AykFqpG7LyV9"
      },
      "outputs": [],
      "source": [
        "vocab = Counter()\n",
        "for ctr in doc_tokens_dict.values():\n",
        "    vocab += ctr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCtgZ2csLyV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273e8364-44d4-401b-a202-67ab5d56d15d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125652"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# number of distinct words in the collection\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn-IFqpRLyV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45711216-d60e-473f-9d59-fd7a27232c14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kill', 33940),\n",
              " ('get', 33557),\n",
              " ('find', 32768),\n",
              " ('take', 30952),\n",
              " ('one', 30675),\n",
              " ('tell', 26790),\n",
              " ('love', 25181),\n",
              " ('leav', 25077),\n",
              " ('father', 23811),\n",
              " ('back', 22968)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "sorted(vocab.items(), key=lambda x: x[1],reverse=True)[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBZzXpxhLyV9"
      },
      "outputs": [],
      "source": [
        "# Storing the term-freq in the dataframe too\n",
        "tokenized_df['Term_Freq'] = pd.Series(doc_tokens_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUvHi5kILyV9"
      },
      "outputs": [],
      "source": [
        "# Creating inverted index\n",
        "# Storing BOTH num of occurred document + the document id for now\n",
        "\n",
        "inverted_index = dict()\n",
        "\n",
        "# storing the document id in case of future use\n",
        "ii_with_ids = dict()\n",
        "\n",
        "for i, val in enumerate(doc_tokens_dict.values()):\n",
        "    for key in val.keys():\n",
        "        if key in inverted_index.keys():\n",
        "            inverted_index[key] += 1\n",
        "        else:\n",
        "            inverted_index[key] = 1\n",
        "        if key not in ii_with_ids.keys():\n",
        "            ii_with_ids[key] = []\n",
        "        ii_with_ids[key].append(i)\n",
        "            \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM9Tr4QPLyV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689adc07-2702-45ff-dc82-770992a72eaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('american', 18014),\n",
              " ('one', 16434),\n",
              " ('take', 16430),\n",
              " ('find', 16086),\n",
              " ('get', 15724),\n",
              " ('leav', 13229),\n",
              " ('love', 13087),\n",
              " ('tri', 12814),\n",
              " ('back', 12606),\n",
              " ('make', 12569)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# top 10 (stemmed) words that appeared in the most documents\n",
        "sorted(inverted_index.items(), key=lambda x: x[1],reverse=True)[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZPiotzbLyV9"
      },
      "source": [
        "## Calculating tf-idf weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOMtJP_RLyV9"
      },
      "source": [
        "As mentioned in HW1: let the `tfidf` of term _t_ in document _d_ be:\n",
        "```\n",
        "tfidf(t, d) = log(count(t, d) + 1) * log(N / df(t))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhXFnpPiLyV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eny3HuiBLyV9"
      },
      "outputs": [],
      "source": [
        "N_doc = len(tokenized_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aZXtXgLLyV9"
      },
      "outputs": [],
      "source": [
        "tf_idf_dict = dict()\n",
        "    \n",
        "for ind, ctr in enumerate(doc_tokens_dict.values()):\n",
        "    val_dict = dict()\n",
        "    for key in ctr.keys():\n",
        "        val_dict[key] = np.log(ctr[key]+1)*np.log(N_doc/inverted_index[key])\n",
        "    tf_idf_dict[ind] = val_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm1RQBQaLyV-"
      },
      "outputs": [],
      "source": [
        "# Storing the tf-idf values in the dataframe too\n",
        "tokenized_df['tfidf'] = pd.Series(tf_idf_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVYT-s_ALyV-"
      },
      "outputs": [],
      "source": [
        "tokenized_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create query functions**"
      ],
      "metadata": {
        "id": "-THxL-OAHJ7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating BM25 scores for each document in each query.\n",
        "\n",
        "For each term i in each query, compute: <br>\n",
        "$log\\frac{(r_i+0.5)/(R-r_i+0.5)}{(n_i-r_i+0.5)/(N-n_i-R+r_i+0.5)}\\cdot \\frac{(k_1+1)f_i}{K+f_i}\\cdot\\frac{(k_2+1)qf_i}{(k_2+qf_i)}$ <br>\n",
        "where $K = k_1((1-b)+b\\cdot\\frac{doc-length}{avg-doc-length})$ and k1=1.2, k2=1000, b=0.75 <br>\n",
        "Adding 1 inside the log avoid negative values for terms with very high document frequency"
      ],
      "metadata": {
        "id": "g0D4sfqtq2vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing length of each document and the average length\n",
        "tokenized_df['Length'] = tokenized_df['Tokens'].apply(len)\n",
        "avg_dl = tokenized_df['Length'].mean()"
      ],
      "metadata": {
        "id": "y5O7Lns-rYM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25 parameters for documents scoring\n",
        "k1 = 1.2\n",
        "b = 0.75\n",
        "k2 = 1000"
      ],
      "metadata": {
        "id": "FdrZQlNHraTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def start_query(query):\n",
        "  solving_query = []\n",
        "  for item in query:\n",
        "    item = item.translate(str.maketrans('', '', string.punctuation))\n",
        "    filtered_sentence = []\n",
        "    for w in word_tokenize(item):\n",
        "      if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "    #ps = PorterStemmer()\n",
        "    #for w in filtered_sentence:\n",
        "    #  w = ps.stem(w)\n",
        "    solving_query.append(filtered_sentence)\n",
        "  df_query = pd.DataFrame({'Origin':[]})\n",
        "  for ele in range(len(solving_query)):\n",
        "    df_query.loc[ele] = [solving_query[ele]]\n",
        "  \n",
        "  df_query['Stemmed'] = df_query['Origin'].apply(lambda x: [stemmer.stem(token) for token in x])\n",
        "  \n",
        "  for ele in range(len(df_query)):\n",
        "    final_result = {}\n",
        "    result = {}\n",
        "    result_set = {}\n",
        "\n",
        "    q_N = len(df_query['Stemmed'][ele])\n",
        "    wordcount_q = Counter(df_query['Stemmed'][ele])\n",
        "    \n",
        "    df_new_query = []\n",
        "    for k in wordcount_q.keys():\n",
        "      df_new_query.append(k)\n",
        "\n",
        "    for i in range(N_doc):\n",
        "      score = 0\n",
        "      for words in df_new_query:\n",
        "        if words in tokenized_df['Term_Freq'][i].keys():\n",
        "          doc_length = tokenized_df['Length'][i]\n",
        "          K = k1 * ((1 - b) + b * (doc_length / avg_dl))\n",
        "          n_i = inverted_index[words]\n",
        "          fi = tokenized_df['Term_Freq'][i][words]\n",
        "          qfi = wordcount_q[words]\n",
        "          sec_1 = (N_doc - n_i + 0.5) / (n_i + 0.5)\n",
        "          sec_2 = ((k1 + 1) * fi) / (K + fi)\n",
        "          sec_3 = ((k2 + 1) * qfi) / (k2 + qfi)\n",
        "          total = np.log(sec_1 * sec_2 * sec_3)\n",
        "        else:\n",
        "          total = 0\n",
        "        score = score + total\n",
        "      result[i] = score\n",
        "    result_set = sorted(result.items(), key = lambda x: x[1], reverse = True)\n",
        "    final_result[ele] = result_set[:10] # You can adjust the number of returned results\n",
        "    print('------------------------' + 'query ' + str(ele + 1) + '------------------------')\n",
        "    for k,v in final_result.items():\n",
        "      for doc in v:\n",
        "        title_name = \"《\" + str(df['Title'][doc[0]]) + \"》 The score: \" + str(doc[1])\n",
        "        print(title_name) \n",
        "        print(df['Plot'][doc[0]])\n",
        "        print('\\n')\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "IW6Ao3L4GgqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start query**"
      ],
      "metadata": {
        "id": "VXOVs9k6Y_uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can do a internal query in this notebook or by uploading a txt file with query statements separated by blank lines."
      ],
      "metadata": {
        "id": "8sbFJXZhGEVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "query = []\n",
        "while True:\n",
        "  mode = input(\"1:internal query || 2:uploading txt file    \")\n",
        "  if len(mode) == 1 and int(mode) == 1:\n",
        "    while True:\n",
        "      single_query = input(\"Please input your query:    \")\n",
        "      query.append(single_query)\n",
        "      finish_or_not = input(\"Continue? Y/N    \")\n",
        "      if finish_or_not != 'Y':\n",
        "        break\n",
        "    break\n",
        "  elif len(mode) == 1 and int(mode) == 2:\n",
        "    txt_file = files.upload()\n",
        "    with open('query.txt') as fp:\n",
        "      query = [p.strip() for p in fp.read().split('\\n\\n')]\n",
        "    break\n",
        "  else:\n",
        "    print(\"Warning: you haven't entered any queries! Do you need to go back and re-enter? Y/N    \")\n",
        "    warning = input()\n",
        "    if warning != 'Y':\n",
        "      break\n",
        "\n",
        "print(\"\\n\")\n",
        "start_query(query)"
      ],
      "metadata": {
        "id": "_6fiDSDEGHFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "YEhq30kYWbzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MAP@10\n",
        "\n",
        "from pandas.core.common import count_not_none\n",
        "qrels = {\n",
        "        1:[1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "        2:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "        3:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "        4:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "        5:[0, 0, 1, 1, 1, 1, 0, 0, 1, 0],\n",
        "        6:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "        7:[0, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
        "        8:[1, 0, 1, 0, 1, 1, 1, 0, 0, 0]\n",
        "}\n",
        "\n",
        "all = 0\n",
        "for k,v in qrels.items():\n",
        "  count = 0\n",
        "  flag = 0\n",
        "  tmp_all = 0\n",
        "  for ele in v:\n",
        "    count = count + 1\n",
        "    if ele != 0:\n",
        "      flag = flag + 1\n",
        "      accuracy = flag / count\n",
        "      tmp_all = tmp_all + accuracy\n",
        "  if flag != 0:\n",
        "    all = all + tmp_all / flag\n",
        "final = all / len(qrels)\n",
        "print('The accuracy: ' + str(final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhZyrwZzWgyD",
        "outputId": "b9e3d9f8-5117-472a-cdca-cffd5d1999ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy: 0.8276128472222222\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OEksudgeLyV8",
        "hTIhxWJaLyV9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}